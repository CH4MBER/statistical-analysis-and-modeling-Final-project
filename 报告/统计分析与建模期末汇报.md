## 2.分类模型

[TOC]



### 1.请进行相应的数据分析，并回答以下问题：

#### （1）不同员工的学历分布是怎样的？

学历分布如下图所示

![education_distribution_layout](education_distribution_layout.png)

具体流程如下：

1. 首先读取数据，使用 `read.csv()` 方法读取员工数据文件 `employee.csv`

    ```r
    employee_data <- read.csv("employee.csv")
    ```

2. 然后对数据进行清洗，去除`Education`列数据缺失的行（经过统计，发现数据中无缺失值，因此在已知此条件的情况下，该步骤可以省略）

    ```r
    employee_data <- employee_data[!is.na(employee_data$Education), ]
    ```

3. 接下来就可以得到各个学历的分布，进而求出比例（比例保留三位小数），并设置对应的图例标签

    ```r
    education_distribution <- table(employee_data$Education)
    education_proportions <- round(education_distribution / sum(education_distribution) * 100, 3)
    labels_with_proportions <- paste(names(education_distribution), "(", education_proportions, "%)", sep = "")
    ```

4. 绘制图表，在一张横向布局的图中分别画出学历分布的柱状图和饼状图，柱状图可以直观显示各个学历的数量，而饼状图可以直观显示各个学历的占比

   ```r
   par(mfrow = c(1, 2), mar = c(4, 4, 4, 2))  
   
   # 柱状图
   barplot_heights <- barplot(education_distribution,
                              main = "Education Background Distribution Barplot",
                              col = "lightblue", ylim = c(0, max(education_distribution) * 1.2))
   text(x = barplot_heights,
        y = education_distribution,
        labels = education_distribution,
        pos = 3, cex = 0.8, col = "blue")
   
   # 饼状图
   pie(education_distribution,
       main = "Education Background Distribution Pie Chart",
       labels = labels_with_proportions,
       col = rainbow(length(education_distribution)),
       cex = 1.2)
   ```

#### （2）不同城市的员⼯服务年限有何差异？差异是否显著？

不同城市的员工服务年限有显著差异，且差异十分显著，具体分析过程如下：

1. 首先读取数据，使用 `read.csv()` 方法读取员工数据文件 `employee.csv`
    ```r
    employee_data <- read.csv("employee.csv")
    ```

2. 然后对数据进行操作，确保`JoiningYear`列，并且过滤掉缺失值和不合理的年份

    ```r
    employee_data$JoiningYear <- as.numeric(as.character(employee_data$JoiningYear))
    employee_data <- subset(employee_data, !is.na(JoiningYear) & JoiningYear <= 2024)
    ```

3. 接下来就可以得到各个员工服务年限的数据了

    ```r
    employee_data$ServiceYears <- 2024 - employee_data$JoiningYear
    ```

4. 根据不同城市的员⼯服务年限画出箱线图

   ```r
   boxplot(ServiceYears ~ City, data = employee_data, main = "Service Years by City", col = "lightgreen")
   ```

   ![service_years_by_city](service_years_by_city.png)

​		从箱线图中是可以看出不同城市的员⼯服务年限是有明显差异的，但我们还可以进行方差分析来进一步确定

5. 进行方差分析

   ```r
   anova_result <- aov(ServiceYears ~ City, data = employee_data)
   summary(anova_result)
   ```

   得到如下结果

   ```shell
                 Df Sum Sq Mean Sq F value Pr(>F)
   City           2    341   170.4   50.12 <2e-16 ***
   Residuals   4650  15812     3.4
   ---
   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
   ```

   可以看出，Pr值 < `2e-16`，这个值远小于0.05，因此我们可以认为不同城市的员工服务年限有显著差异，且差异十分显著

#### （3）薪资等级与当前领域经验之间是否存在某种关联？

薪资等级与当前领域经验之间并不存在某种关联，具体分析过程如下：

1. 首先读取数据，使用 `read.csv()` 方法读取员工数据文件 `employee.csv`
    ```r
    employee_data <- read.csv("employee.csv")
    ```

2. 然后对数据进行操作，删除` PaymentTier` 或 `ExperienceInCurrentDomain `列中有缺失值的行（经过统计，发现数据中无缺失值，因此在已知此条件的情况下，该步骤可以省略）

    ```r
    employee_data$JoiningYear <- as.numeric(as.character(employee_data$JoiningYear))
    employee_data <- subset(employee_data, !is.na(JoiningYear) & JoiningYear <= 2024)
    ```

3. 假设薪资等级与当前领域经验之间存在某种关联，进行卡方检验

    ```r
    contingency_table_raw <- table(employee_data$PaymentTier, employee_data$ExperienceInCurrentDomain)
    chi_test_raw <- chisq.test(contingency_table_raw)
    print(chi_test_raw)
    ```

    得到如下结果

    ```r
    
            Pearson's Chi-squared test
    
    data:  contingency_table_raw
    X-squared = 20.106, df = 14, p-value = 0.1268
    
    Warning message:
    In chisq.test(contingency_table_raw) : Chi-squared近似算法有可能不准
    
    ```

    可以看到p值为0.1268，大于0.05，但是有Chi-squared近似算法有可能不准的提示，这是因为有些数据的频次小于5

4. 为了解决上述问题，查看哪些数据的频次小于5

   ```r
   contingency_table_raw <- table(employee_data$PaymentTier, employee_data$ExperienceInCurrentDomain)
   print(contingency_table_raw)
   ```

   得到如下结果

   ```shell
      
         0   1   2   3   4   5   6   7
     1  25  36  51  41  43  45   1   1
     2  66  90 252 150 184 174   1   1
     3 264 432 784 595 704 700   6   7
   ```

   因此考虑将同一薪资等级的当前领域年份大于4的数据合并

5. 将同一薪资等级的当前领域年份大于4的数据合并

    ```r
    employee_data$ExperienceInCurrentDomain <- as.numeric(as.character(employee_data$ExperienceInCurrentDomain))
    employee_data$ExperienceGroup <- cut(employee_data$ExperienceInCurrentDomain,
                                          breaks = c(-Inf, 0, 1, 2, 3, 4, Inf),
                                          labels = c("0 years", "1 year", "2 years", "3 years", "4 years", "4+years"))
    ```
    
 6. 对合并后的数据在进行卡方检验
    
    ```r
       contingency_table_merged <- table(employee_data$PaymentTier, employee_data$ExperienceGroup)
       chi_test_merged <- chisq.test(contingency_table_merged)
       print(chi_test_merged)
    ```
      得到如下结果：
    
    ```shell
       
               Pearson's Chi-squared test
       
       data:  contingency_table_merged
       X-squared = 18.139, df = 10, p-value = 0.05267
       
    ```
    可以看到p值为0.05267，大于0.05，因此可以认为薪资等级与当前领域经验之间并不存在某种关联

### 2.请通过构建⻉叶斯⽹络预测员⼯是否会离职，评估模型质量

1. 首先读取数据，使用 `read.csv()` 方法读取员工数据文件 `employee.csv`

   ```r
   employee_data <- read.csv("employee.csv")
   ```

2. 对数据进行处理，删除包含缺失值的行（经计算，`sum(is.na(employee_data)`为0），然后将每列数据都转为因子型

   ```R
   if (sum(is.na(employee_data)) > 0) {
     employee_data <- na.omit(employee_data)
   }
   employee_data <- as.data.frame(lapply(employee_data, factor))
   ```

3. 导入`bnlearn`包，构建并训练贝叶斯网络

   ```r
   bn_structure <- hc(employee_data)
   bn_model <- bn.fit(bn_structure, data = employee_data)
   ```

4. 对模型进行预测，并通过计算准确率、精确率、召回率、`F1-Score`，对模型质量进行评估

   ```r
   predicted <- predict(bn_model, node = "LeaveOrNot", data = employee_data)
   conf_matrix <- table(predicted, employee_data$LeaveOrNot)
   accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
   precision <- conf_matrix[2,2] / sum(conf_matrix[2,])
   recall <- conf_matrix[2,2] / sum(conf_matrix[,2])
   f1_score <- 2 * (precision * recall) / (precision + recall)
   print(paste("Accuracy:", accuracy))
   print(paste("Precision:", precision))
   print(paste("Recall:", recall))
   print(paste("F1-Score:", f1_score))
   ```

   得到如下结果

   ```r
   [1] "Accuracy: 0.809800128949065"
   [1] "Precision: 0.890710382513661"
   [1] "Recall: 0.509375"
   [1] "F1-Score: 0.648111332007952"
   ```

5. 对结果进行分析

   1. 准确率（模型预测正确的样本占总样本的比例）：0.8098
      - 准确率较高，说明模型总体上能够较好地区分正类和负类
      - 当数据集中类别不平衡时（例如，正类样本明显少于负类），高准确率可能会掩盖模型对少数类的表现不佳
   2. 精确率（在所有被预测为正类的样本中，实际为正类的比例）：0.8907
      - 精确率很高（接近 90%），说明模型预测为正类时大多数是正确的，这意味着误报率较低
   3. 召回率（在所有实际为正类的样本中，被模型正确预测为正类的比例）：0.5094
      - 召回率较低（约 51%），表明模型漏报了许多正类样本
   4. `F1-Score`（Precision 和 Recall 的加权调和平均值，用于平衡两者的表现）：0.6481
      - `F1-Score `中等（约 0.65），表明模型在精确率和召回率之间存在一定的权衡
      - 虽然模型的精确率较高，但召回率相对较低，整体性能较为平衡，但仍有改进空间

   总而言之，模型其总体上能够较好地区分正类和负类。然而，在类别不平衡的情况下，高准确率可能掩盖了模型对少数类的表现。精确率很高，模型预测为正类时大多数是正确的，误报率较低。但是召回率较低，模型漏报了许多正类样本。模型在精确率和召回率之间存在一定的权衡。尽管精确率较高，召回率偏低，整体表现平衡，但仍有改进空间。

### 3.请构建逻辑回归模型对员⼯是否会离职进⾏预测，并通过模型解读员⼯离职的影响因素

1. 首先读取数据，使用 `read.csv()` 方法读取员工数据文件 `employee.csv`

   ```r
   employee_data <- read.csv("employee.csv")
   ```

2. 对数据进行处理，删除包含缺失值的行（经计算，`sum(is.na(employee_data)`为0），然后将每列数据都转为因子型

   ```R
   if (sum(is.na(employee_data)) > 0) {
     employee_data <- na.omit(employee_data)
   }
   employee_data <- as.data.frame(lapply(employee_data, factor))
   ```

3. 导入必要的包，并划分训练集和测试集（80%训练，20%测试）

   ```r
   trainIndex <- createDataPartition(employee_data$LeaveOrNot, p = 0.8, list = FALSE)
   train_data <- employee_data[trainIndex, ]
   test_data <- employee_data[-trainIndex, ]
   ```

4. 构建逻辑回归模型，并查看模型总结

   ```r
   logit_model <- glm(LeaveOrNot ~ Education + City + PaymentTier + Gender + EverBenched + ExperienceInCurrentDomain + JoiningYear + Age,
                      data = train_data, 
                      family = binomial(link = "logit"))
   summary(logit_model)
   ```

   得到如下结果：

   ```r
   Call:
   glm(formula = LeaveOrNot ~ Education + City + PaymentTier + Gender + 
       EverBenched + ExperienceInCurrentDomain + JoiningYear + Age, 
       family = binomial(link = "logit"), data = train_data)
   
   Coefficients:
                               Estimate Std. Error z value Pr(>|z|)    
   (Intercept)                 0.102617   0.425425   0.241 0.809392    
   EducationMasters            1.144595   0.123385   9.277  < 2e-16 ***
   EducationPHD               -1.066426   0.323185  -3.300 0.000968 ***
   CityNew Delhi              -0.487141   0.128292  -3.797 0.000146 ***
   CityPune                    0.606177   0.110603   5.481 4.24e-08 ***
   PaymentTier2                0.981385   0.199376   4.922 8.55e-07 ***
   PaymentTier3               -0.601452   0.178663  -3.366 0.000762 ***
   GenderMale                 -0.994731   0.091543 -10.866  < 2e-16 ***
   EverBenchedYes              0.255723   0.144750   1.767 0.077287 .
   ExperienceInCurrentDomain1 -0.009854   0.213850  -0.046 0.963246
   ExperienceInCurrentDomain2 -0.358030   0.208030  -1.721 0.085241 .
   ExperienceInCurrentDomain3  0.032920   0.231086   0.142 0.886719
   ExperienceInCurrentDomain4 -0.521484   0.252524  -2.065 0.038914 *
   ExperienceInCurrentDomain5 -0.832759   0.267558  -3.112 0.001855 ** 
   ExperienceInCurrentDomain6 -2.551136   2.088323  -1.222 0.221852
   ExperienceInCurrentDomain7  0.733272   0.928533   0.790 0.429697
   JoiningYear2013             0.449043   0.166757   2.693 0.007086 **
   JoiningYear2014             0.175504   0.169352   1.036 0.300048
   JoiningYear2015             0.235935   0.167072   1.412 0.157897
   JoiningYear2016             0.050241   0.183823   0.273 0.784612
   JoiningYear2017            -0.712867   0.174272  -4.091 4.30e-05 ***
   JoiningYear2018             6.434689   0.610593  10.538  < 2e-16 ***
   Age23                      -0.487889   0.597928  -0.816 0.414520
   Age24                       0.061193   0.445856   0.137 0.890835
   Age25                      -0.144825   0.454882  -0.318 0.750198
   Age26                      -0.087528   0.461846  -0.190 0.849687
   Age27                       0.375102   0.469741   0.799 0.424564
   Age28                      -0.657715   0.421360  -1.561 0.118539
   Age29                      -0.540246   0.451182  -1.197 0.231150
   Age30                      -0.437794   0.444792  -0.984 0.324984
   Age31                      -0.460702   0.478979  -0.962 0.336130
   Age32                       0.031594   0.469366   0.067 0.946334
   Age33                      -0.440314   0.494708  -0.890 0.373441    
   Age34                      -0.281716   0.481853  -0.585 0.558782
   Age35                      -0.676773   0.504409  -1.342 0.179688
   Age36                      -0.723042   0.470903  -1.535 0.124676
   Age37                      -0.580487   0.476005  -1.219 0.222655    
   Age38                      -0.227333   0.474435  -0.479 0.631821
   Age39                      -0.746710   0.487989  -1.530 0.125973
   Age40                      -0.798218   0.490391  -1.628 0.103584
   Age41                      -0.201725   0.514883  -0.392 0.695214
   ---
   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
   
   (Dispersion parameter for binomial family taken to be 1)
   
       Null deviance: 4791.7  on 3722  degrees of freedom
   Residual deviance: 3310.0  on 3682  degrees of freedom
   AIC: 3392
   
   Number of Fisher Scoring iterations: 7
   ```

   对上述数据分析，可以得知员工离职的影响因素，但在分析之前，还需要先查看下准确率

5. 计算并输出准确率

   ```r
   train_pred_prob <- predict(logit_model, train_data, type = "response")
   test_pred_prob <- predict(logit_model, test_data, type = "response")
   train_pred_class <- ifelse(train_pred_prob > 0.5, 1, 0)
   test_pred_class <- ifelse(test_pred_prob > 0.5, 1, 0)
   train_conf_matrix <- table(Predicted = train_pred_class, Actual = train_data$LeaveOrNot)
   train_accuracy <- sum(diag(train_conf_matrix)) / sum(train_conf_matrix)
   train_precision <- train_conf_matrix[2,2] / sum(train_conf_matrix[2,])
   train_recall <- train_conf_matrix[2,2] / sum(train_conf_matrix[,2])
   train_f1 <- 2 * (train_precision * train_recall) / (train_precision + train_recall)
   test_conf_matrix <- table(Predicted = test_pred_class, Actual = test_data$LeaveOrNot)
   test_accuracy <- sum(diag(test_conf_matrix)) / sum(test_conf_matrix)
   test_precision <- test_conf_matrix[2,2] / sum(test_conf_matrix[2,])
   test_recall <- test_conf_matrix[2,2] / sum(test_conf_matrix[,2])
   test_f1 <- 2 * (test_precision * test_recall) / (test_precision + test_recall)
   cat("训练集准确率:", train_accuracy, "\n")
   cat("训练集精确率:", train_precision, "\n")
   cat("训练集召回率:", train_recall, "\n")
   cat("训练集F1分数:", train_f1, "\n")
   cat("测试集准确率:", test_accuracy, "\n")
   cat("测试集精确率:", test_precision, "\n")
   cat("测试集召回率:", test_recall, "\n")
   cat("测试集F1分数:", test_f1, "\n")
   ```

   得到如下结果

   ```r
   训练集准确率: 0.8119796 
   训练集精确率: 0.8152174 
   训练集召回率: 0.5859375
   训练集F1分数: 0.6818182
   测试集准确率: 0.7892473
   测试集精确率: 0.7627119
   测试集召回率: 0.5625
   测试集F1分数: 0.647482
   ```

   可以看出虽然召回率稍微有些低，但是由于模型准确率、精确率都比较高，因此可以认为模型能够较好地区分正类和负类，因此我们通过模型解读员工离职的影响因素是合理的

6. 对模型总结结果进行分析，解读员工离职的影响因素：

   1. Education (学历)

      ```r
      EducationMasters            1.144595   0.123385   9.277  < 2e-16 ***
      EducationPHD               -1.066426   0.323185  -3.300 0.000968 ***
      ```

      - `EducationMasters`的Pr值 < `2e-16`，远小于0.001，且系数为正数，说明硕士学历的员工比非硕士学历的员工离职的可能性更高，且极为显著
      - `EducationPHD`的Pr值为0.000968，小于0.001，且系数为负数，说明博士学历的员工比非博士学历的员工离职的可能性更低，且十分显著

   2. City（城市）

      ```r
      CityNew Delhi              -0.487141   0.128292  -3.797 0.000146 ***
      CityPune                    0.606177   0.110603   5.481 4.24e-08 ***
      ```

      - `CityNew Delhi`的Pr值为0.000146，小于0.001，且系数为负数，说明在`New Delhi`的员工比其他城市的员工离职的可能性更低，且十分显著
      - `CityPune `的Pr值为`4.24e-08`，远小于0.001，且系数为正数，说明在`Pune`的员工比其他城市的员工离职的可能性更高，且极为显著

   3. `PaymentTier` (薪资等级)

      ```r
      PaymentTier2                0.981385   0.199376   4.922 8.55e-07 ***
      PaymentTier3               -0.601452   0.178663  -3.366 0.000762 ***
      ```

      - `PaymentTier2`的Pr值为`8.55e-07`，远小于0.001，且系数为正数，说明薪资等级为2的员工比其他薪资等级的员工离职的可能性更高，且极为显著
      - `PaymentTier3   `的Pr值为0.000762，小于0.001，且系数为负数，说明薪资等级为3的员工比其他薪资等级的员工离职的可能性更低，且十分显著

   4. Gender（性别认同）

      ```R
      GenderMale                 -0.994731   0.091543 -10.866  < 2e-16 ***
      ```

      - `GenderMale`的Pr值Pr值 < `2e-16`，远小于0.001，且系数为负数，说明性别认同为男性员工比非男性员工离职的可能性更低，且极为显著

   5. `EverBenched`（是否曾有过未被分配⼯作的临时状态）

      ```r
      EverBenchedYes              0.255723   0.144750   1.767 0.077287 .
      ```

      - `EverBenchedYes`的Pr值为0.078，接近0.05，且系数为正数，说明有过未被分配⼯作的临时状态的员工比没有过的员工离职的可能性更高，但不显著

   6. `ExperienceInCurrentDomain` (当前领域工作年数)

      ```r
      ExperienceInCurrentDomain2 -0.358030   0.208030  -1.721 0.085241 .
      ExperienceInCurrentDomain4 -0.521484   0.252524  -2.065 0.038914 *
      ExperienceInCurrentDomain5 -0.832759   0.267558  -3.112 0.001855 ** 
      ```

      - `ExperienceInCurrentDomain2`的Pr值为为0.085，接近0.05，且系数为负数，说明当前领域工作年数为2的员工比其他当前领域工作年数的员工离职的可能性更低，但不显著
      - `ExperienceInCurrentDomain4   `的Pr值为0.038914，小于0.05，且系数为负数，说明当前领域工作年数为4的员工比其他当前领域工作年数的员工离职的可能性更低，且显著
      - `ExperienceInCurrentDomain5   `的Pr值为0.001855，小于0.05，且系数为负数，说明当前领域工作年数为5的员工比其他当前领域工作年数的员工离职的可能性更低，且更显著

   7. `JoiningYear` (加入年份)

      ```R
      JoiningYear2013             0.449043   0.166757   2.693 0.007086 **
      JoiningYear2017            -0.712867   0.174272  -4.091 4.30e-05 ***
      JoiningYear2018             6.434689   0.610593  10.538  < 2e-16 ***
      ```

      - `JoiningYear2013`的Pr值为0.007086，小于0.05，且系数为正数，说明加入年份为2013的员工比其他加入年份的员工离职的可能性更高，但不显著
      - `JoiningYear2017   `的Pr值为`4.30e-05`，远小于0.001，且系数为负数，说明说明加入年份为2017的员工比其他加入年份的员工离职的可能性更低，且极为显著
      - `JoiningYear2018   `的Pr值<` 2e-16`，远小于0.001，且系数为正数，高达 6.434689，说明加入年份为2018的员工比其他加入年份的员工离职的可能性更高，且更加极为显著

### 4.模型可能存在的不⾜并给出优化建议

模型的分析和优化建议可以分为以下几点：

1. 数据不平衡：离职员工在数据中的比例较低，导致模型偏向预测“未离职”类别，表现为较高的准确率和精确率，但召回率较低。

   优化建议：

   - 采用过采样（如SMOTE）或欠采样方法来平衡数据集。

   - 调整分类的阈值，通过提高召回率来优化模型性能。

2. 多重共线性问题：特征之间可能存在较强的相关性，如“工作经验”和“年龄”这类变量，可能影响模型的稳定性和预测精度。

   优化建议：

   - 使用主成分分析（PCA）或L1正则化（Lasso）来减少冗余特征，避免共线性影响。
   - 对相关性较强的特征进行去除或合并，保持模型的简洁性。

3. 特征选择问题：现有特征可能不完全捕捉员工离职的所有影响因素，可能缺乏更细粒度的工作满意度等变量。

   优化建议：

   - 添加一些工作满意度相关的特征，例如工作压力、工作环境、与上司的关系等，这些因素可能对离职决策有显著影响

4. 过拟合问题：模型在训练集上的表现较好，但在测试集上的召回率较低，存在过拟合现象。

   优化建议：

   - 采用交叉验证来调整模型参数，确保模型具备更好的泛化能力。
   - 使用正则化技术（如L2正则化）来减轻过拟合。
   - 通过简化模型（例如去除某些不显著的特征）来提升模型的稳定性。


​      
